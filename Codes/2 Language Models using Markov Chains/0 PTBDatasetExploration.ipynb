{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of PTB Dataset and Corpus object\n",
    "\n",
    "- This notebook presents the exploration of PTB dataset. \n",
    "\n",
    "    - Previews the first ten lines of the dataset. \n",
    "    - Creates a Corpus object \n",
    "\n",
    "- The Corpus object represents the training data as a sequence (list) of integer token IDs. It builds a Dictionary that assigns each unique word an unique index in order of first appearance, appends an '\\<eos\\>' token after each line.\n",
    "\n",
    "- Corpus stores the data in:\n",
    "    - corpus.data\n",
    "\n",
    "- The vocabulary and mappings are available via:\n",
    "    - corpus.dictionary.word2idx\n",
    "    - corpus.dictionary.idx2word\n",
    "\n",
    "- Vocabulary size is given by:\n",
    "    - len(corpus.dictionary).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab\n",
    "# Upload the folder containing this file to google drive.\n",
    "\n",
    "import sys, os\n",
    "# Checking if the notebook is opened in google colab\n",
    "#If YES, mount the google drive and change the directory\n",
    "if 'google.colab' in sys.modules:\n",
    "\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # change path to the folder\n",
    "    path = '/content/drive/My Drive/xxxxx/xxxxx'\n",
    "    print(path)\n",
    "    #os.chdir changes the current working directory\n",
    "    os.chdir(path)\n",
    "    !pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_mclm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Previewing ptb/train.txt:\n",
      " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter\n",
      " pierre <unk> N years old will join the board as a nonexecutive director nov. N\n",
      " mr. <unk> is chairman of <unk> n.v. the dutch publishing group\n",
      " rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate\n",
      " a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than N years ago researchers reported\n",
      " the asbestos fiber <unk> is unusually <unk> once it enters the <unk> with even brief exposures to it causing symptoms that show up decades later researchers said\n",
      " <unk> inc. the unit of new york-based <unk> corp. that makes kent cigarettes stopped using <unk> in its <unk> cigarette filters in N\n",
      " although preliminary findings were reported more than a year ago the latest results appear in today 's new england journal of medicine a forum likely to bring new attention to the problem\n",
      " a <unk> <unk> said this is an old story\n",
      " we 're talking about years ago before anyone heard of asbestos having any questionable properties\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'ptb'\n",
    "#Preview the first ten lines of the dataset\n",
    "preview_ptb_file(data_folder,\"train.txt\", num_lines=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the corpus object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use train data to build the model\n",
    "corpus = Corpus(data_folder, 'train.txt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Corpus object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Corpus Information:\n",
      "Vocabulary size: 10000\n",
      "Number of tokens in training data: 929589\n",
      "\n",
      "First 5 tokens and their indices:\n",
      "Index:    0, Word: aer\n",
      "Index:    1, Word: banknote\n",
      "Index:    2, Word: berlitz\n",
      "Index:    3, Word: calloway\n",
      "Index:    4, Word: centrust\n",
      "\n",
      "Vocabulary Examples:\n",
      "First 10 words in vocabulary: ['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec']\n",
      "Last 10 words in vocabulary: ['lung-cancer', 'bikers', 'bofors', 'parsow', 'caci', 'isi', 'chestman', 'tci', 'trecker', 'unilab']\n",
      "\n",
      "Indices for common words:\n",
      "'the': 32\n",
      "'a': 35\n",
      "'<eos>': 24\n",
      "'<unk>': 26\n",
      "\n",
      "Sample sequence converted back to words:\n",
      "workers exposed to it more than N years ago researchers\n",
      "\n",
      "Number of unique tokens used in training data: 10000\n",
      "Total vocabulary size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Basic Corpus Information:\")\n",
    "print(f\"Vocabulary size: {len(corpus.dictionary)}\")\n",
    "print(f\"Number of tokens in training data: {len(corpus.data)}\")\n",
    "\n",
    "# Look at the first few tokens and their indices\n",
    "n = 5\n",
    "print(f\"\\nFirst {n} tokens and their indices:\")\n",
    "first_n_indices = corpus.data[:n]\n",
    "for idx in first_n_indices:\n",
    "    word = corpus.dictionary.idx2word[idx]\n",
    "    print(f\"Index: {idx:4d}, Word: {word}\")\n",
    "\n",
    "# Get some statistics about the vocabulary\n",
    "print(\"\\nVocabulary Examples:\")\n",
    "print(\"First 10 words in vocabulary:\", corpus.dictionary.idx2word[:10])\n",
    "print(\"Last 10 words in vocabulary:\", corpus.dictionary.idx2word[-10:])\n",
    "\n",
    "# Look up some specific words\n",
    "sample_words = ['the', 'a', '<eos>', '<unk>']\n",
    "print(\"\\nIndices for common words:\")\n",
    "for word in sample_words:\n",
    "    if word in corpus.dictionary.word2idx:\n",
    "        print(f\"'{word}': {corpus.dictionary.word2idx[word]}\")\n",
    "    else:\n",
    "        print(f\"'{word}' not in vocabulary\")\n",
    "\n",
    "# Convert a small sequence back to words\n",
    "print(\"\\nSample sequence converted back to words:\")\n",
    "sample_sequence = corpus.data[100:110]  # Get 10 tokens\n",
    "reconstructed_text = ' '.join([corpus.dictionary.idx2word[idx] for idx in sample_sequence])\n",
    "print(reconstructed_text)\n",
    "\n",
    "# Get some basic statistics\n",
    "unique_indices = len(set(corpus.data))\n",
    "print(f\"\\nNumber of unique tokens used in training data: {unique_indices}\")\n",
    "print(f\"Total vocabulary size: {len(corpus.dictionary)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
