{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da434a8",
   "metadata": {},
   "source": [
    "#  Introduction to Neural Networks using PyTorch\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9151f959",
   "metadata": {},
   "source": [
    "### Q3  Using NN to recognize handwritten digits \n",
    "\n",
    "\n",
    "In the final part of this assignment, we will be building a neural network to classify images to their respective digits.  \n",
    "\n",
    "You will build and train a model on the classic **MNIST Handwritten Digits** dataset. Each grayscale image is a $28 \\times 28$ matrix/tensor that looks like so:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" width=\"500\" />\n",
    "\n",
    "MNIST is a classification problem and the task is to take in an input image and classify them into one of ten buckets: the digits from $0$ to $9$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FIRST\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda667dc",
   "metadata": {},
   "source": [
    "### Loading an external dataset\n",
    "\n",
    "The cell below imports the MNIST dataset, which is already pre-split into train and test sets.  \n",
    "\n",
    "The download takes approximately 63MB of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce62735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL – THIS DOWNLOADS THE MNIST DATASET\n",
    "# RUN THIS CELL BEFORE YOU RUN THE REST OF THE CELLS BELOW\n",
    "#Install torchvision\n",
    "from torchvision import datasets\n",
    "\n",
    "# This downloads the MNIST datasets ~63MB\n",
    "mnist_train = datasets.MNIST(\"./\", train=True, download=True)\n",
    "mnist_test  = datasets.MNIST(\"./\", train=False, download=True)\n",
    "\n",
    "x_train = mnist_train.data.reshape(-1, 784) / 255\n",
    "y_train = mnist_train.targets\n",
    "    \n",
    "x_test = mnist_test.data.reshape(-1, 784) / 255\n",
    "y_test = mnist_test.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092f6c4",
   "metadata": {},
   "source": [
    "### 3.1 - Define the model architechure and implement the forward pass \n",
    "Create a 3-layer network in the `__init__` method of the model `DigitNet`.  \n",
    "These layers are all `Linear` layers and should correspond to the following the architecture:\n",
    "\n",
    "<img src=\"img_linear_nn.png\" width=\"600\">\n",
    "\n",
    "In our data, a given image $x$ has been flattened from a 28x28 image to a 784-length array.\n",
    "\n",
    "After initializing the layers, stitch them together in the `forward` method. Your network should look like so:\n",
    "\n",
    "$$x \\rightarrow \\text{Linear(512)} \\rightarrow \\text{ReLU} \\rightarrow \\text{Linear(128)} \\rightarrow \\text{ReLU} \\rightarrow \\text{Linear(10)} \\rightarrow \\text{Softmax} \\rightarrow \\hat{y}$$\n",
    "\n",
    "**Softmax Layer**: The final softmax activation is commonly used for classification tasks, as it will normalizes the results into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1] which is nice because we are able to avoid binary classification and accommodate as many classes or dimensions in our neural network model.\n",
    "\n",
    "*Note: When using `torch.softmax(...)` on the final layer, ensure you are applying it on the correct dimension (as you did in NumPy via the `axis` argument in popular methods)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d04f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitNet(nn.Module):\n",
    "    def __init__(self, input_dimensions, num_classes): # set the arguments you'd need\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        YOUR CODE HERE\n",
    "        \n",
    "        - your network should work for any input and output size \n",
    "            – add appropriate arguments in the object constructor\n",
    "        - create the 3 layers (and a ReLU layer) using the torch.nn layers API\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs the forward pass for the network.\n",
    "        \n",
    "        PARAMS:\n",
    "            x : the input tensor (batch size is the entire dataset)\n",
    "            \n",
    "        RETURNS\n",
    "            the output of the entire 3-layer model\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        YOUR CODE\n",
    "        \n",
    "        - pass the inputs through the sequence of layers\n",
    "        - run the final output through the Softmax function on the right dimension!\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356b9ad",
   "metadata": {},
   "source": [
    "### Q3.2 Training Loop  \n",
    "\n",
    "As demonstrated in Section 3.2, implement the function `train_model` that performs the following for every epoch/iteration:\n",
    "\n",
    "1. set the optimizer's gradients to zero\n",
    "2. forward pass\n",
    "3. calculate the loss\n",
    "4. backpropagate using the loss\n",
    "5. take an optimzer step to update weights\n",
    "\n",
    "This time, use the Adam optimiser to train the network.  \n",
    "Use Cross-Entropy Loss, since we are performing a classification.  \n",
    "Train for 20 epochs.  \n",
    "\n",
    "*Note: refer to the command glossary to find out how to instantiate optimisers, losses, and more*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, epochs=20):\n",
    "    \"\"\"\n",
    "    Trains the model for 20 epochs/iterations\n",
    "    \n",
    "    PARAMS:\n",
    "        x_train : a tensor of training features of shape (60000, 784)\n",
    "        y_train : a tensor of training labels of shape (60000, 1)\n",
    "        epochs  : number of epochs, default of 20\n",
    "        \n",
    "    RETURNS:\n",
    "        the final model \n",
    "    \"\"\"\n",
    "    model = DigitNet(784, 10)\n",
    "    optimiser = ... # use Adam\n",
    "    loss_fn = ...   # use cross-entropy loss\n",
    "\n",
    "    for i in range(epochs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return model\n",
    "                \n",
    "digit_model = train_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fdee35",
   "metadata": {},
   "source": [
    "### Q3.3 - Explore your model  \n",
    "\n",
    "Now that we have trained the model, let us run some predictions on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a demonstration: You can use this cell for exploring your trained model\n",
    "\n",
    "idx = 0 # try on some index\n",
    "\n",
    "scores = digit_model(x_test[idx:idx+1])\n",
    "_, predictions = torch.max(scores, 1)\n",
    "print(\"true label:\", y_test[idx].item())\n",
    "print(\"pred label:\", predictions[0].item())\n",
    "\n",
    "plt.imshow(x_test[idx].numpy().reshape(28, 28), cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc94586",
   "metadata": {},
   "source": [
    "### Q3.4 - Evaluate the model  \n",
    "\n",
    "Now that we have trained the model, we should evaluate it using our test set.  \n",
    "We will be using the accuracy (whether or not the model predicted the correct label) to measure the model performance.  \n",
    "\n",
    "Since our model takes in a (n x 784) tensor and returns a (n x 10) tensor of probability scores for each of the 10 classes, we need to convert the probability scores into the actual predictions by taking the index of the maximum probability.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5684246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(scores, labels):\n",
    "    \"\"\"\n",
    "    helper function that returns accuracy of model (out of 100%)\n",
    "    PARAMS:\n",
    "        scores : the raw softmax scores of the network\n",
    "        label : the ground truth labels\n",
    "        \n",
    "    RETURNS:\n",
    "        accuracy out of 100%\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "scores = digit_model(x_test) # n x 10 tensor\n",
    "get_accuracy(scores, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
