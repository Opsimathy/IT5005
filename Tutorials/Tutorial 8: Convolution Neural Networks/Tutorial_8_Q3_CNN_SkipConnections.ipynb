{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip Connection Challenge\n",
    "\n",
    "Skip connections enable very deep neural network through uninterrupted gradient flows. The objective of this question is to study the issues in including the skip connection in a CNN network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3a: Implementation of Skip Connection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider this basic CNN structure shown in the code block below. The objective is to implement the skip connection from the output of Layer 1 to the output of Layer 3. Layer 1's output (a1) should be added to Layer 3's output (a3). The issue with this connection is the shape mismatch between a1 and a3.\n",
    "\n",
    "First answer the following questions. You can assume that the batch size is B and the CIFAR-10 is an RGB dataset with a height and width of 32 pixels each.\n",
    "\n",
    "- **Shape of tensor a1_** : _________________________________\n",
    "\n",
    "\n",
    "- **Shape of tensor a1**:  _________________________________\n",
    "\n",
    "\n",
    "\n",
    "- **Shape of tensor a2_**: _________________________________\n",
    "\n",
    "\n",
    "\n",
    "- **Shape of tensor a2**: _________________________________\n",
    "\n",
    "\n",
    "- **Shape of tensor a3_**: _________________________________\n",
    "\n",
    "\n",
    "\n",
    "- **Shape of tensor a3**: _________________________________\n",
    "\n",
    "\n",
    "Use this information to implement the skip connection in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnectionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SkipConnectionCNN, self).__init__()\n",
    "        \n",
    "        # Layer 1: Conv2d(in_channels = 3, out_channels = 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=3, stride=1, padding=1)\n",
    "        # MaxPool2d(2, 2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Layer 2: Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, stride=1, padding=1)\n",
    "\n",
    "        # MaxPool2d(2, 2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Layer 3: Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride=1, padding=1)\n",
    "                \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Define skip connection from the output of Layer 1 (a1) to output of Layer 3 (a3)\n",
    "        # Hint: a1 and a3 needs to be added and the shapes of a1 and a3 must be compatible for addition\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Main path\n",
    "        #Input to Layer 1\n",
    "        a1_ = self.relu(self.conv1(x))    \n",
    "        a1 = self.pool1(a1_)              \n",
    "        #Layer 1 to Layer 2\n",
    "        a2_ = self.relu(self.conv2(a1))   \n",
    "        a2 = self.pool2(a2_)              \n",
    "        #Layer 2 to Layer 3\n",
    "        a3_ = self.relu(self.conv3(a2))   \n",
    "        a3 = self.pool2(a3_)              \n",
    "       \n",
    "        # Implement skip connection from Layer 1 to Layer 3  \n",
    "        # Combine a3 with a1\n",
    "        # a3skip = a3 + a1\n",
    "        # Hint: Check the shapes a1 and a3; they must be compatible for addition\n",
    "        \n",
    "        return a3skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3b: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "skip_model = SkipConnectionCNN()\n",
    "\n",
    "# Test the implementation\n",
    "def test_network(model):\n",
    "\n",
    "    # Create random input tensor with CIFAR-10 dimensions\n",
    "    x = torch.randn(1, 3, 32, 32) \n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    \n",
    "    # Print shapes\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# Run test\n",
    "test_network(skip_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
