{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uXNY-Rz-4yzp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30995,
     "status": "ok",
     "timestamp": 1762592597568,
     "user": {
      "displayName": "Rajendra Prasad",
      "userId": "14653680398158491278"
     },
     "user_tz": -480
    },
    "id": "uXNY-Rz-4yzp",
    "outputId": "e00d0d72-426b-4978-c29d-193b6f4091dc"
   },
   "outputs": [],
   "source": [
    "# For Google Colab\n",
    "# Upload the folder containing this file to google drive.\n",
    "import sys, os\n",
    "# Checking if the notebook is opened in google colab\n",
    "#If YES, mount the google drive and change the directory\n",
    "if 'google.colab' in sys.modules:\n",
    "\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # change path to the folder\n",
    "    path = 'xxxxx/xxxxx'\n",
    "    print(path)\n",
    "    #os.chdir changes the current working directory\n",
    "    os.chdir(path)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IoM6Xol-40Wb",
   "metadata": {
    "executionInfo": {
     "elapsed": 7556,
     "status": "ok",
     "timestamp": 1762592605136,
     "user": {
      "displayName": "Rajendra Prasad",
      "userId": "14653680398158491278"
     },
     "user_tz": -480
    },
    "id": "IoM6Xol-40Wb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils_gpt_ import *\n",
    "from transformer_ import *\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3e338",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1762592605151,
     "user": {
      "displayName": "Rajendra Prasad",
      "userId": "14653680398158491278"
     },
     "user_tz": -480
    },
    "id": "f8b3e338"
   },
   "outputs": [],
   "source": [
    "def train_steps(model, train_loader, val_loader, optimizer, scheduler, device,\n",
    "                total_steps=25000, log_interval=100, eval_interval=1000,\n",
    "                save_path=\"trained_gpt_model.pt\"):\n",
    "    import random, math\n",
    "    model.train()\n",
    "    global_step = 0\n",
    "    total_mean_loss, total_token_nll, total_tokens = 0.0, 0.0, 0\n",
    "\n",
    "    all_idxs = list(range(len(train_loader)))\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    while global_step < total_steps:\n",
    "        step_idx = random.choice(all_idxs)\n",
    "        input_ids, targets = train_loader.get_batch(step_idx)\n",
    "        input_ids = input_ids.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, loss = model(input_ids, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        tokens_per_batch = targets.numel()\n",
    "        total_mean_loss += loss.item()\n",
    "        total_token_nll += loss.item() * tokens_per_batch\n",
    "        total_tokens += tokens_per_batch\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % log_interval == 0:\n",
    "            avg_mean = total_mean_loss / max(1, global_step)\n",
    "            avg_token_true = total_token_nll / max(1, total_tokens)\n",
    "            ppl = math.exp(avg_token_true)\n",
    "            print(f\"Step {global_step}/{total_steps} | LR {scheduler.get_last_lr()[0]:.6f} | \"\n",
    "                  f\"Avg Train Loss (mean): {avg_mean:.4f} | NLL/token: {avg_token_true:.4f} | PPL: {ppl:.2f}\")\n",
    "\n",
    "        if global_step % eval_interval == 0 or global_step == total_steps:\n",
    "            model.eval()\n",
    "            fixed_val_indices = list(range(len(val_loader)))  # full val\n",
    "            avg_val_loss, val_ppl = evaluate_on_fixed_subset(model, val_loader, device, fixed_val_indices)\n",
    "            print(f\"[Eval] Step {global_step} | Val NLL/token: {avg_val_loss:.4f} | Val PPL: {val_ppl:.2f}\")\n",
    "            if avg_val_loss < best_val:\n",
    "                best_val = avg_val_loss\n",
    "                best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            model.train()\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    torch.save({\n",
    "        \"model_config\": model.get_model_config(),\n",
    "        \"model_state_dict\": model.state_dict()\n",
    "    }, save_path)\n",
    "    print(f\"Saved best model to {save_path} (best Val NLL/token {best_val:.4f})\")\n",
    "\n",
    "\n",
    "def run_step_training(config):\n",
    "    device = get_device()\n",
    "\n",
    "    # Data\n",
    "    corpus_common = CorpusCommon(path=config['data_path'], add_bos=False, add_eos=True)\n",
    "    dictionary = corpus_common.dictionary\n",
    "    save_vocabulary_dict(dictionary, config['vocab_save_path'])\n",
    "\n",
    "    train_loader = GPTDataLoader.from_tensor(corpus_common.train, dictionary, config['batch_size'], config['seq_len'])\n",
    "    val_loader   = GPTDataLoader.from_tensor(corpus_common.valid, dictionary, config['batch_size'], config['seq_len'])\n",
    "    print(f\"Train stats: {train_loader.get_stats()}\")\n",
    "    print(f\"Valid stats: {val_loader.get_stats()}\")\n",
    "\n",
    "    # Model\n",
    "    model = GPT(\n",
    "        vocab_size=len(dictionary),\n",
    "        d_model=config['d_model'],\n",
    "        num_heads=config['num_heads'],\n",
    "        num_layers=config['num_layers'],\n",
    "        d_ff=config['d_ff'],\n",
    "        max_seq_length=config['max_seq_length'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # Optimizer (simple version; consider param groups to exclude bias/LayerNorm from weight decay)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                                  lr=config['learning_rate'],\n",
    "                                  weight_decay=config['weight_decay'])\n",
    "\n",
    "    # Scheduler: base it on total_steps \n",
    "    # 25000 is the default fallback value (used only if total_steps is not defined)\n",
    "    total_steps = config.get('total_steps', 25000)\n",
    "    warmup_steps = max(1, int(config.get('warmup_ratio', 0.05) * total_steps))\n",
    "    base_lr = config['learning_rate']\n",
    "    min_lr = config.get('min_lr', 1e-6)\n",
    "\n",
    "    if config.get('scheduler_type', 'cosine').lower() == 'linear':\n",
    "        lambda_fn = get_linear_warmup_decay_lambda_with_floor(total_steps, warmup_steps, min_lr, base_lr)\n",
    "    else:\n",
    "        lambda_fn = get_cosine_warmup_decay_lambda_with_floor(total_steps, warmup_steps,\n",
    "                                                              config.get('cosine_cycles', 0.5), min_lr, base_lr)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_fn)\n",
    "\n",
    "    # Train by steps\n",
    "    train_steps(model, train_loader, val_loader, optimizer, scheduler, device,\n",
    "                total_steps=total_steps,\n",
    "                log_interval=config.get('log_interval', 100),\n",
    "                eval_interval=config.get('eval_interval', 1000),\n",
    "                save_path=config.get('model_save_path', 'trained_gpt_model.pt'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd524938",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd524938",
    "outputId": "897b8cd3-83e3-4090-981e-28bef733765e"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "        'data_path': 'ptb',\n",
    "        'vocab_save_path': 'vocabulary.txt',\n",
    "        'model_save_path': 'trained_gpt_model.pt',\n",
    "        'batch_size': 32,\n",
    "        'seq_len': 256,\n",
    "        'd_model': 256,\n",
    "        'num_heads': 4,\n",
    "        'num_layers': 4,\n",
    "        'd_ff': 2048,\n",
    "        'max_seq_length': 1024,\n",
    "        'dropout': 0.95,\n",
    "        'learning_rate': 1e-4,        # consider lowering from 1e-3\n",
    "        'weight_decay': 0.01,\n",
    "        'scheduler_type': 'cosine',\n",
    "        'warmup_ratio': 0.05,\n",
    "        'cosine_cycles': 0.5,\n",
    "        'min_lr': 1e-6,\n",
    "        'total_steps': 20000,\n",
    "        'log_interval': 1000,\n",
    "        'eval_interval': 1000,\n",
    "    }\n",
    "run_step_training(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c4d4c",
   "metadata": {
    "id": "be0c4d4c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
